{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0ec404-5a3a-4046-b37e-2e4b7802b929",
   "metadata": {},
   "source": [
    "# División del conjunto de datos\n",
    "\n",
    "A la hora de entrenar un modelo una parte fundamental es dividir el conjunto de \n",
    "datos en 3 secciones importantes:\n",
    "\n",
    "1. Datos de entrenamiento (entre un 60% o 70% del conjunto)\n",
    "2. Datos de validación (entre un 15% o 20% del conjunto)\n",
    "   - Estos sirven para probar el modelo en caso de que el entrenamiento\n",
    "     arroje valores de overfitting lo que nos permitirá reevaluar el\n",
    "     modelo y/o aplicar técnicas como eleminiación de características o \n",
    "     regularización (penalizar ligeramnete los valores de peso para que \n",
    "     la función hipotesis no se ajuste tan perfectamente a los datos de\n",
    "     entrenamiento)\n",
    "3. Datos de prueba (entre un 15% o 20% del conjunto)\n",
    "   - Estos datos se usan como prueba final para verificar que el modelo\n",
    "     tiene un bajo nivel de error tanto en el conjunto de entrenamiento\n",
    "     como en el de validamiento y no se ha sobre entrenado para ninguno\n",
    "     de los dos.\n",
    "\n",
    "Solamente así nos podemos asegurar que el modelo se entrenará correctamente y predecirá adecuadamente nuevos valores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef98cc3-88e8-4509-bcf6-d9232f165861",
   "metadata": {},
   "source": [
    "## 1. Lectura del conjunto de datos\n",
    "\n",
    "Se continuará trabajando con los datos de flujos de red normales o anómalos *NSL-KDD*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd009294-dd7f-4fb7-8098-a61529a6adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc4b520-2cca-46f2-b7ac-2311b73a731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para cargar dataset en formato arff a un df de Pandas\n",
    "def load_kdd_dataset(data_path):\n",
    "    \"\"\"Lectura del conjunto de datos NSL-KDD.\"\"\"\n",
    "    with open(data_path, 'r') as train_set:\n",
    "        dataset = arff.load(train_set)\n",
    "    attributes = [attr[0] for attr in dataset[\"attributes\"]]\n",
    "    return pd.DataFrame(dataset[\"data\"], columns=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025dae38-d82c-468c-aa38-3dc48ac196e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_kdd_dataset('../datasets/NSL-KDD/KDDTrain+.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ddce324-1a03-4721-a64f-0707124adb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   duration                     125973 non-null  float64\n",
      " 1   protocol_type                125973 non-null  object \n",
      " 2   service                      125973 non-null  object \n",
      " 3   flag                         125973 non-null  object \n",
      " 4   src_bytes                    125973 non-null  float64\n",
      " 5   dst_bytes                    125973 non-null  float64\n",
      " 6   land                         125973 non-null  object \n",
      " 7   wrong_fragment               125973 non-null  float64\n",
      " 8   urgent                       125973 non-null  float64\n",
      " 9   hot                          125973 non-null  float64\n",
      " 10  num_failed_logins            125973 non-null  float64\n",
      " 11  logged_in                    125973 non-null  object \n",
      " 12  num_compromised              125973 non-null  float64\n",
      " 13  root_shell                   125973 non-null  float64\n",
      " 14  su_attempted                 125973 non-null  float64\n",
      " 15  num_root                     125973 non-null  float64\n",
      " 16  num_file_creations           125973 non-null  float64\n",
      " 17  num_shells                   125973 non-null  float64\n",
      " 18  num_access_files             125973 non-null  float64\n",
      " 19  num_outbound_cmds            125973 non-null  float64\n",
      " 20  is_host_login                125973 non-null  object \n",
      " 21  is_guest_login               125973 non-null  object \n",
      " 22  count                        125973 non-null  float64\n",
      " 23  srv_count                    125973 non-null  float64\n",
      " 24  serror_rate                  125973 non-null  float64\n",
      " 25  srv_serror_rate              125973 non-null  float64\n",
      " 26  rerror_rate                  125973 non-null  float64\n",
      " 27  srv_rerror_rate              125973 non-null  float64\n",
      " 28  same_srv_rate                125973 non-null  float64\n",
      " 29  diff_srv_rate                125973 non-null  float64\n",
      " 30  srv_diff_host_rate           125973 non-null  float64\n",
      " 31  dst_host_count               125973 non-null  float64\n",
      " 32  dst_host_srv_count           125973 non-null  float64\n",
      " 33  dst_host_same_srv_rate       125973 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       125973 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  125973 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  125973 non-null  float64\n",
      " 37  dst_host_serror_rate         125973 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     125973 non-null  float64\n",
      " 39  dst_host_rerror_rate         125973 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     125973 non-null  float64\n",
      " 41  class                        125973 non-null  object \n",
      "dtypes: float64(34), object(8)\n",
      "memory usage: 40.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0dc32c-a381-4ec4-9dc7-69510aa21e36",
   "metadata": {},
   "source": [
    "## 2. División del conjunto de datos\n",
    "\n",
    "Separar el dataset actual en 3subconjuntos:\n",
    "\n",
    " * DF de entrenamiento\n",
    " * DF de prueba\n",
    " * DF de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25ac4439-6e49-4d97-8531-c522c0949417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar el 60% para entrenamiento y 40% para train/validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(df, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f89c15f1-dd89-4905-8a17-aa3e4db14589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75583"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set) # Tamaño de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec728b32-fb34-40c0-ad97-710025a426a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50390"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set) # Tamaño de pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a9eda08-e7d6-40bd-9e2d-70ffa59b3653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar el subconjunto de test 50/50 para obtener el set de validacion\n",
    "val_set, test_set = train_test_split(test_set, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd25b421-fb07-4a60-8d64-03b64fa4bc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25195"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b32a1915-0f07-49cd-ae71-1a2c05e5d069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 75583\n",
      "Tamaño del conjunto de validacion: 25195\n",
      "Tamaño del conjunto de prueba: 25195\n"
     ]
    }
   ],
   "source": [
    "print(f'Tamaño del conjunto de entrenamiento: {len(train_set)}')\n",
    "print(f'Tamaño del conjunto de validacion: {len(val_set)}')\n",
    "print(f'Tamaño del conjunto de prueba: {len(test_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9eb71a-3f3e-41b7-8368-21b68385ecf8",
   "metadata": {},
   "source": [
    "## 3. División del conjunto NO ALEATORIO\n",
    "\n",
    "La función de sklearn *train_test_split* mezcla por defecto el conjunto de datos cada vez que ejecutamos volvemos a ingresar al script y lo ejecutamos. Esto hace de que manera indirecta el modelo terminará conociendo todo el conjunto sin importar que lo dividamos volviendo al problema del **overfitting**. Para solucionar esto la función incluye los parámetros *random_state* donde le damos una semilla de generación única y *shuffle* en false donde indicamos que no mezcle la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc937722-a68b-4f9d-ac6a-be39cb3f3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evitar la mezcla de los datos\n",
    "train_set, test_set = train_test_split( \n",
    "    df, test_size=0.4,\n",
    "    random_state=42,\n",
    "    shuffle=False \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8726f369-54e3-40a0-820f-ea309d9fb555",
   "metadata": {},
   "source": [
    "El problema de hacer esto es que puede que algunas características como el *protocol_type* tenga coincidentemente valores de un tipo x en las primeras filas de todo el conjunto, si no hace una mezcla el modelo no será entrenado correctamente y podrá generara valores erroneos en el futuro.\n",
    "\n",
    "Para solucionar este problema se puede identificar las características propensas a ocurrir esto (generalmente las caraterísticas categóricas/string) y usamos el parámetro **stratify** indicando el nombre de la columna que se va a encargar de esparcir homogéneamente a traves de todo el conjunto de datos general.\n",
    "\n",
    "* **Aún así shuffle=False sigue siendo útil cuando se manejan grandes volumenes de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c920aa4-686c-4dff-8db4-4fcecf48dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split( \n",
    "    df,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    stratify=df['protocol_type'] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aab11b-923e-4825-83b0-3d291ae45009",
   "metadata": {},
   "source": [
    "## 4. Generar una función para división del conjunto de datos\n",
    "\n",
    "Crear una función para reusar la división del conjunto de datos en los 3 subconjuntos mencionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "629cfa49-48c4-42bb-bc88-42d40ca6cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción de una función que realice el particionado completo\n",
    "def train_val_test_split(df, rstate=42, shuffle=True, stratify=None):\n",
    "\n",
    "    # Strat solo si le pasamos la columa a dispersar\n",
    "    strat = df[stratify] if stratify else None \n",
    "    \n",
    "    train_set, test_set = train_test_split(\n",
    "        df,\n",
    "        test_size=0.4,\n",
    "        random_state=rstate, # Semilla de generación aleatoria única\n",
    "        shuffle=shuffle, # Si se hace o no un shuffle\n",
    "        stratify=strat # Columna a dispersar si la hay\n",
    "    )\n",
    "\n",
    "    # Se repite el proceso para obtener el validation_set\n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    \n",
    "    val_set, test_set = train_test_split(\n",
    "        test_set,\n",
    "        test_size=0.5,\n",
    "        random_state=rstate,\n",
    "        shuffle=shuffle,\n",
    "        stratify=strat\n",
    "    )\n",
    "    \n",
    "    return (train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aed4f3ca-b513-4ddc-b389-8f9089d8e19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud inicial del conjunto: 125973\n"
     ]
    }
   ],
   "source": [
    "print(f'Longitud inicial del conjunto: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23531aa1-dba1-4df2-b3b2-5575d9942d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = train_val_test_split(\n",
    "    df, # Le pasamos el ds original\n",
    "    stratify='protocol_type' # Pasamos el nombre de la columna que queramos dispersar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "662b7115-7a8b-4a24-9695-372e7ad300e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 75583\n",
      "Tamaño del conjunto de validacion: 25195\n",
      "Tamaño del conjunto de prueba: 25195\n"
     ]
    }
   ],
   "source": [
    "print(f'Tamaño del conjunto de entrenamiento: {len(train_set)}')\n",
    "print(f'Tamaño del conjunto de validacion: {len(val_set)}')\n",
    "print(f'Tamaño del conjunto de prueba: {len(test_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce477ba-98f3-42c8-9de5-73e22e0924ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
